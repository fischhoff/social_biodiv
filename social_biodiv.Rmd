---
title: "social_biodiv"
author: "Ilya"
date: "6/23/2018"
#using github document, which makes for static maps, because github displays .md but html is too big for github
output: github_document
---

#####To do: 
#####1) try python wrapper for ebird data #####(https://pypi.org/project/ebird-api/)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#####install and load reticulate 
```{r, echo = FALSE}
# pkgTest is a helper function to load packages and install packages only when they are not installed yet.
pkgTest <- function(x)
{
  if (x %in% rownames(installed.packages()) == FALSE) {
    install.packages(x, dependencies= TRUE)    
  }
  library(x, character.only = TRUE)
}
#reticulate is needed to use python in R 
neededPackages <- c("reticulate", "leaflet", "mapview", "ggplot2", "rebird", "rinat" )#this is just a placeholder, installing dev version of reticulate
for (package in neededPackages){pkgTest(package)}
devtools::install_github("yihui/knitr")

```

#####install using py_install
```{r,echo=FALSE}
#py_install("nose")
#py_install("tornado")
#py_install("matplotlib")
py_install("flickrapi")

```

#####import python packages
```{r}
flickrapi <- import("flickrapi")
```

#####import flickrapi, load keys in python, do search for birds in Santa Monica Hills
```{python}
#####################################################################################
#import packages
import flickrapi
import pandas as pd
import csv
#####################################################################################
#key and secret
api_key_file = "/Users/fischhoff/ilya documents/R/social_biodiv/flickr_api_key.txt"
with open(api_key_file, "r") as keyfile:
    api_key = keyfile.read()
api_key

#get secret

api_secret_file = "/Users/fischhoff/ilya documents/R/social_biodiv/flickr_api_secret.txt"
with open(api_secret_file, "r") as keyfile:
    secret_api_key = keyfile.read()
#####################################################################################
#do search
#https://www.flickr.com/groups/51035612836@N01/discuss/72157668638670202/
flickr = flickrapi.FlickrAPI(api_key, secret_api_key, format='parsed-json')
extras='url_m,geo,tags,owner_name,date_taken,date_upload,description'
#bbox

LLX = -119.065606
LLY = 34.09166
URX=-118.540862
URY = 34.142754
bb = str(LLX) + ',' + str(LLY) + ',' + str(URX) + ',' + str(URY)
query = 'birds'
#search
page_no = 1
parameters = { 'bbox': bb, 
'tags': query, 
#'tag_mode':'all', #note: if using tag_mode: all then comment out tags: query
'per_page':250, 
'page': page_no, 
'has_geo':1, 
'accuracy':14,
'extras': extras}
init = flickr.photos.search(**parameters)
pages = init['photos']['pages']
print(pages)
total = init['photos']['total']
print(total)

#####################################################################################
#output to csv
df = pd.DataFrame.from_dict(init)
d = df['photos']['photo']
d_first_page= pd.DataFrame.from_records(d, columns = ['id', 'owner', 'description', 'latitude', 'longitude'])

d_first_page.to_csv('flickr.bird.csv')
```

#####make map of flickr data for photos in Santa Monica Mtns w/ "birds" as tag
```{r}
F = read.csv('flickr.bird.csv')
#find centroid of area of interest
clat =median(F$latitude)
clon = median(F$longitude)
#Fmap <- leaflet(F) %>%
leaflet(F) %>%

  addTiles() %>%
      setView(lat = clat, lng=clon, zoom =10) %>%

    #add polygons for dma.ggl 
  addCircleMarkers(fillOpacity = 0.1)
#mapshot(Fmap, file = "flickr.bird.santamonica.png")
#Fmap
```

#####import flickrapi, load keys in python, do general search of Santa Monica Hills -- not restricted to any tag
```{python}
import flickrapi
import pandas as pd
#####################################################################################
#key and secret
api_key_file = "/Users/fischhoff/ilya documents/R/social_biodiv/flickr_api_key.txt"
with open(api_key_file, "r") as keyfile:
    api_key = keyfile.read()
api_key

#get secret
api_secret_file = "/Users/fischhoff/ilya documents/R/social_biodiv/flickr_api_secret.txt"
with open(api_secret_file, "r") as keyfile:
    secret_api_key = keyfile.read()
#print(secret_api_key)

#####################################################################################
#do search
flickr = flickrapi.FlickrAPI(api_key, secret_api_key, format='parsed-json')
extras='url_m,geo,tags,owner_name,date_taken,date_upload,description'
#bbox

LLX = -119.065606
LLY = 34.09166
URX=-118.540862
URY = 34.142754
bb = str(LLX) + ',' + str(LLY) + ',' + str(URX) + ',' + str(URY)
page_no = 1
parameters = { 'bbox': bb, 
'tag_mode':'all', #note: if using tag_mode: all then comment out tags: query
'per_page':250, 
'page': page_no, 
'has_geo':1, 
'accuracy':15,
'extras': extras}
init = flickr.photos.search(**parameters)
#init = flickr.groups.pools.getPhotos(**parameters)#https://stackoverflow.com/questions/29651576/python-flickr-api-for-group-search-and-get-image-data-set
pages = init['photos']['pages']
print("pages")
print(pages)
total = init['photos']['total']
print("photos")
print(total)

#####################################################################################
#write to csv
df = pd.DataFrame.from_dict(init)
d = df['photos']['photo']
d_first_page= pd.DataFrame.from_records(d, columns = ['id', 'owner', 'description', 'latitude', 'longitude'])
print("shape of first page")
print(d_first_page.shape)

d_first_page.to_csv('flickr.all.sm.csv')
```

#####make map of flickr data for photos in Santa Monica Mtns w/ no restriction on tag
```{r}
F = read.csv('flickr.all.sm.csv')
#find centroid of area of interest
clat =median(F$latitude)
clon = median(F$longitude)
Fmap <- leaflet(F) %>%
  addTiles() %>%
      setView(lat = clat, lng=clon, zoom =10) %>%

    #add polygons for dma.ggl 
  addCircleMarkers(fillOpacity = 0.1)
mapshot(Fmap, file = "flickr.bird.santamonica.png")

Fmap
#ggplot(data = F, mapping = aes(x = longitude, y = latitude))+
#  geom_point()
```
#eBird
#####get recent ebird data using R package rebird; plot with fill color darkness proportional to #birds seen
```{r}
X = -118.75#approx x and y for Santa Monica Mountains
Y = 34.12
E = ebirdgeo(species=NULL, lat = Y, lng = X, back = 30, dist= 50)
head(E)
names(E)
pal <- colorNumeric("viridis", NULL)

leaflet(E) %>%
  addTiles() %>%
      setView(lat = Y, lng=X, zoom =9) %>%
  addCircleMarkers(lng=E$lng, lat = E$lat, fillOpacity = 0.1, opacity =0.05, fillColor=~pal(E$howMany)                    )

```

#iNaturalist
#####get iNat data for Santa Monica Mountains using R package rinat; plot on map with fill color equal to userid
```{r}
#vignette:  https://cran.r-project.org/web/packages/rinat/vignettes/rinatVignette.html
LLX = -119.065606
LLY = 34.09166
URX=-118.540862
URY = 34.142754
#southern latitude, western longitude, northern latitude, and eastern longitude
bounds <- c(LLY, LLX, URY, URX)
I <- get_inat_obs(query = NULL, bounds = bounds, year = 2018, geo=TRUE, maxresults = 10000)
dim(I)

```

#####plot iNat data on map with fill color equal to iconic name
```{r}
I = subset(I, iconic_taxon_name !="")
Y = mean(LLY, URY)
X = median(LLX, URX)
pal <- colorNumeric("viridis", NULL)

leaflet(I) %>%
  addTiles() %>%
      setView(lat = Y, lng=X, zoom =10) %>%
  addCircleMarkers(lng=I$longitude, lat = I$latitude, fillOpacity = 0.15, opacity =0.0, 
                   radius = 5,
                   color =~pal(as.numeric(as.factor(I$iconic_taxon_name))),
                               fillColor=~pal(as.numeric(as.factor(I$iconic_taxon_name)))
                   )
```

